{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Classify 404 Canonical Poems\n",
    "\n",
    "Uses Llama-3-8B with your 52 gold-standard examples as few-shot prompts.\n",
    "\n",
    "**Runtime**: ~30-60 minutes on Colab GPU\n",
    "\n",
    "**Output**: CSV with all 28 classification columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "!pip install transformers torch accelerate pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mount Google Drive (if you want to save results there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload your files\n",
    "# 1. gold_standard_52_poems_with_narrative_level.csv\n",
    "# 2. 448_poems_to_classify.csv\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Load Mistral-7B-Instruct (ungated, no access request needed)\nmodel_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=500,\n    temperature=0.3,\n    top_p=0.9,\n)\n\nprint(\"✓ Mistral-7B-Instruct loaded\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load gold-standard examples\n",
    "gold_df = pd.read_csv('gold_standard_52_poems_with_narrative_level.csv')\n",
    "print(f\"Loaded {len(gold_df)} gold-standard poems\")\n",
    "\n",
    "# Load poems to classify\n",
    "classify_df = pd.read_csv('448_poems_to_classify.csv')\n",
    "print(f\"Loaded {len(classify_df)} poems to classify\")\n",
    "\n",
    "# Select 5 diverse gold-standard examples for few-shot prompt\n",
    "few_shot_examples = gold_df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Build few-shot prompt\n",
    "def build_classification_prompt(poem_title, poem_author, poem_year, few_shot_examples):\n",
    "    prompt = \"\"\"You are a literary scholar classifying English poetry across 28 metadata dimensions.\n",
    "\n",
    "Here are 5 example classifications:\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Add few-shot examples\n",
    "    for idx, row in few_shot_examples.iterrows():\n",
    "        prompt += f\"\"\"EXAMPLE {idx+1}:\n",
    "Title: {row['title']}\n",
    "Author: {row['author']}\n",
    "Year: {row['year_approx']}\n",
    "Period: {row['period']}\n",
    "Literary Movement: {row['literary_movement']}\n",
    "Register: {row['register']}\n",
    "Rhetorical Genre: {row['rhetorical_genre']}\n",
    "Mode: {row['mode']}\n",
    "Narrative Level: {row['narrative_level']}\n",
    "Meter: {row['meter']}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    prompt += f\"\"\"Now classify this poem using the same schema. Return ONLY a JSON object with these fields:\n",
    "period, literary_movement, register, rhetorical_genre, discursive_structure, discourse_type, \n",
    "narrative_level, diegetic_mimetic, focalization, person, deictic_orientation, addressee_type, \n",
    "deictic_object, temporal_orientation, temporal_structure, tradition, mode, genre, \n",
    "stanza_structure, meter, rhyme\n",
    "\n",
    "POEM TO CLASSIFY:\n",
    "Title: {poem_title}\n",
    "Author: {poem_author}\n",
    "Year: {poem_year}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Classify all poems\nresults = []\ncheckpoint_interval = 50\n\nfor idx, row in tqdm(classify_df.iterrows(), total=len(classify_df)):\n    try:\n        prompt = build_classification_prompt(\n            row['title'], \n            row['author'], \n            row['year_approx'],\n            few_shot_examples\n        )\n        \n        # Generate classification\n        output = pipe(prompt)\n        response = output[0]['generated_text'][len(prompt):].strip()\n        \n        # Try to parse JSON\n        try:\n            classification = json.loads(response)\n        except:\n            # Fallback: extract JSON from response\n            import re\n            json_match = re.search(r'\\{[^}]+\\}', response, re.DOTALL)\n            if json_match:\n                classification = json.loads(json_match.group())\n            else:\n                classification = {}\n        \n        # Add poem info\n        result = {\n            'title': row['title'],\n            'author': row['author'],\n            'year_approx': row['year_approx'],\n            **classification\n        }\n        results.append(result)\n        \n        # Checkpoint every 50 poems (save to both temp and Google Drive)\n        if (idx + 1) % checkpoint_interval == 0:\n            checkpoint_df = pd.DataFrame(results)\n            # Save to temp (for download)\n            checkpoint_df.to_csv(f'checkpoint_{idx+1}.csv', index=False)\n            # Save to Google Drive (persistent - survives runtime disconnects)\n            checkpoint_df.to_csv(f'/content/drive/MyDrive/checkpoint_{idx+1}.csv', index=False)\n            print(f\"✓ Checkpoint saved: {idx+1} poems classified (saved to Drive)\")\n            \n    except Exception as e:\n        print(f\"Error on poem {idx}: {row['title']} - {e}\")\n        results.append({'title': row['title'], 'author': row['author'], 'error': str(e)})\n\nprint(\"\\n✓ Classification complete!\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save final results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('404_poems_classified.csv', index=False)\n",
    "print(f\"✓ Saved {len(results_df)} classifications to 404_poems_classified.csv\")\n",
    "\n",
    "# Also save to Google Drive\n",
    "results_df.to_csv('/content/drive/MyDrive/404_poems_classified.csv', index=False)\n",
    "print(\"✓ Saved to Google Drive\")\n",
    "\n",
    "# Download\n",
    "files.download('404_poems_classified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Quality check\n",
    "print(\"\\nQuality Check:\")\n",
    "print(f\"Total poems: {len(results_df)}\")\n",
    "print(f\"Successful: {results_df['period'].notna().sum()}\")\n",
    "print(f\"Errors: {results_df['period'].isna().sum()}\")\n",
    "print(\"\\nSample results:\")\n",
    "print(results_df[['title', 'author', 'period', 'register', 'mode']].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}